# LVLM-evaluation-pipeline
Multimodal Reasoning Audit Pipeline for Vision-Language Models (VLMs) â€” evaluates VLMs beyond final-answer accuracy using vision-dependence tests, hallucination checks, and claim-level faithfulness scoring across VQA/OCR/document benchmarks.
